# 任务自适应提问系统 (TAQ)

一个智能家庭服务机器人系统，根据当前任务和视觉场景分析生成与上下文相关的问题。机器人能够根据特定的家庭任务调整其提问策略，并与人类操作员协作执行物理动作。

[English](README.md) | 中文

## 核心概念

**任务自适应提问**使机器人能够：
- 🎯 基于视觉场景分析生成特定任务问题
- 🔄 随着任务进展调整提问策略
- 🤝 与人类操作员协作执行物理任务
- 📚 从对话历史中学习以改善未来互动

## 主要特性

### 🤖 智能提问系统
- **视觉场景分析**：集成VLM的实时摄像头画面分析
- **任务感知问题**：基于当前家庭任务的情境敏感问题生成
- **自适应对话**：问题基于对话历史和用户回应而演进
- **推理显示**：展示机器人每个问题背后的分析过程

### 🏠 家庭服务集成
- **操作员协作**：为人类操作员提供清晰的物理动作执行指令
- **任务配置**：基于JSON的任务和提示管理
- **会话管理**：持久的对话历史和上下文感知
- **实时状态**：VLM处理和图像捕获期间的实时更新

### 🌐 网页界面
- **实时视频流**：带有任务状态覆盖的实时摄像头画面
- **交互式聊天**：用户与机器人之间的无缝对话
- **对话历史**：完整的交互日志，包含时间戳和推理过程
- **响应式设计**：支持桌面和移动设备的友好界面

## 安装

1. 安装所需依赖：
```bash
pip install -r requirements.txt
```

2. 确保摄像头已连接并可访问。

3. 在 `config/prompt_config.json` 中配置任务：
```json
{
  "task_description": "organize the table"
}
```

## 任务自适应提问工作原理

### 1. **任务上下文设置**
在 `config/prompt_config.json` 中配置机器人的当前任务：
```json
{
  "task_description": "organize the kitchen counter"
}
```

### 2. **视觉场景分析**
机器人捕获视频帧并在当前任务上下文中进行分析，考虑：
- 场景中的物体和布局
- 任务要求和限制
- 先前的对话上下文
- 对话历史中的用户偏好

### 3. **自适应问题生成**
基于分析，机器人生成以下特点的问题：
- 特定于当前任务上下文
- 基于之前的对话内容
- 引导有效的任务完成
- 考虑用户偏好的交互风格

### 4. **协作执行**
当用户回应时，机器人会：
- 理解用户偏好和指令
- 在需要物理动作时生成清晰的操作员指令
- 提供上下文相关的后续问题
- 基于用户反馈调整未来的提问

## 使用方法

1. 启动TAQ网页应用：
```bash
python web_app.py
```

2. 通过 `http://localhost:5050` 访问界面

3. **任务自适应交互流程**:
   - 📸 **提问**: 机器人在任务上下文中分析当前场景
   - 💬 **回应**: 用户提供偏好或指令
   - 🤖 **机器人适应**: 系统更新理解并生成后续问题
   - 📋 **操作员指令**: 物理任务执行的清晰指导
   - 🔄 **继续**: 过程重复，适应不断变化的任务上下文

4. **查看历史**: 点击"📋 History"查看完整的任务交互日志

## 界面组件

### 视频区域
- **实时视频流**：实时摄像头画面
- **状态栏**：当前系统状态及视觉指示器
- **任务显示**：显示当前配置的任务
- **捕获按钮**：触发图像捕获和问题生成

### 聊天区域
- **对话区域**：显示完整的对话历史
- **机器人消息**：包含推理和问题
- **用户回应**：您对机器人问题的答案
- **回应输入**：输入回应的文本框

### 状态指示器
- 🟢 **就绪**：系统准备接受新问题
- 🟡 **思考中**：VLM处理中（动画效果）
- 🟡 **捕获中**：正在截图
- 🔴 **错误**：系统发生错误

## 任务自适应配置

### 任务适应示例

系统根据配置的任务调整其提问方式：

**厨房整理任务**:
```json
{
  "task_description": "organize the kitchen counter"
}
```
- 问题聚焦于食品安全、可达性和工作流程
- 考虑烹饪模式和电器使用
- 适应用户的烹饪风格偏好

**客厅清洁任务**:
```json
{
  "task_description": "tidy up the living room"
}
```  
- 关于家具布置和装饰的问题
- 考虑家庭使用模式和舒适度
- 适应美学偏好和功能性

**工作流程适应**:
机器人的提问策略随任务进展而演进：
1. **初始评估**: 关于偏好和优先级的广泛问题
2. **聚焦询问**: 关于挑战性区域或物品的具体问题
3. **执行指导**: 关于实施细节的详细问题
4. **质量保证**: 关于满意度和调整的问题

### 摄像头设置
在 `web_app.py` 中修改摄像头设置：
```python
# 更改摄像头分辨率
self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)

# 更改摄像头ID（用于多摄像头）
camera_id = 0  # 尝试 1, 2 等其他摄像头
```

## API端点

- `GET /` - 主网页界面
- `GET /video_feed` - 视频流端点
- `POST /capture_and_ask` - 捕获帧并生成问题
- `POST /respond` - 提交用户回应
- `GET /conversation` - 获取对话历史
- `GET /status` - 获取当前状态和任务

## WebSocket事件

- `status_update` - 实时状态更新
- `connect/disconnect` - 客户端连接事件

## 故障排除

### 摄像头问题
- 确保已授予摄像头权限
- 尝试不同的摄像头ID（0, 1, 2等）
- 检查摄像头是否被其他应用程序使用

### VLM连接问题
- 验证 `vlmCall_ollama.py` 中的VLM API端点
- 检查到VLM服务器的网络连接
- 确保模型可用且已加载

### 性能问题
- 降低视频分辨率以提高性能
- 增加视频流的帧延迟
- 检查系统资源（CPU、内存）

## TAQ系统架构

```
taq/  # 任务自适应提问系统
├── web_app.py              # 网页界面和视频流
├── robot_service.py        # 业务逻辑和任务适应
├── vlmCall_ollama.py       # 基础VLM API集成
├── video_question_system.py # TAQ的CLI界面
├── config/
│   └── prompt_config.json  # 任务特定提示和配置
├── templates/
│   └── index.html         # 响应式网页界面
├── test_architecture.py   # 架构验证测试
├── requirements.txt       # Python依赖
└── README.md             # TAQ系统文档
```

### 架构原则

**分层设计**:
- **API层** (`vlmCall_ollama.py`): 纯VLM API通信
- **业务逻辑层** (`robot_service.py`): 任务适应和问题生成
- **应用层** (`web_app.py`, `video_question_system.py`): 用户界面

**任务适应核心**:
- 基于JSON的任务和提示配置
- 上下文感知的问题生成
- 对话历史集成
- 操作员协作协议

## 开发与定制

### 扩展任务自适应能力

1. **新任务类型**: 在 `config/prompt_config.json` 中添加任务特定提示
2. **问题策略**: 修改 `robot_service.py` 中的业务逻辑
3. **UI增强**: 更新 `templates/index.html` 中的网页界面
4. **集成**: 通过 `vlmCall_ollama.py` 添加新的VLM功能

### 任务适应研究

TAQ系统为以下研究提供基础：
- **情境感知机器人技术**: 机器人如何根据特定任务调整行为
- **人机协作**: 任务完成的有效提问策略
- **对话式AI**: 随时间学习和适应的对话系统
- **视觉语言集成**: 将视觉感知与自然语言理解相结合

### 应用示例

- **老年护理**: 基于个人需求和偏好的自适应协助
- **工业培训**: 复杂程序的情境感知指导
- **教育机器人**: 通过自适应提问实现个性化学习
- **智能家居系统**: 学习家庭模式的智能协助

该系统展示了机器人如何通过在正确的时间提出正确的问题，根据任务上下文和用户偏好调整其方法，从而成为更有效的协作者。